{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 793 files belonging to 20 classes.\n",
      "Found 199 files belonging to 20 classes.\n",
      "Epoch 1/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 275ms/step - accuracy: 0.1072 - loss: 3.0029 - val_accuracy: 0.1608 - val_loss: 3.0196 - learning_rate: 1.0000e-04\n",
      "Epoch 2/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 239ms/step - accuracy: 0.6118 - loss: 1.5884 - val_accuracy: 0.2915 - val_loss: 2.9149 - learning_rate: 1.0000e-04\n",
      "Epoch 3/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 244ms/step - accuracy: 0.7998 - loss: 0.9491 - val_accuracy: 0.3920 - val_loss: 2.8943 - learning_rate: 1.0000e-04\n",
      "Epoch 4/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 238ms/step - accuracy: 0.8614 - loss: 0.6997 - val_accuracy: 0.4523 - val_loss: 2.8497 - learning_rate: 1.0000e-04\n",
      "Epoch 5/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 241ms/step - accuracy: 0.9163 - loss: 0.4864 - val_accuracy: 0.4724 - val_loss: 2.8435 - learning_rate: 1.0000e-04\n",
      "Epoch 6/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 246ms/step - accuracy: 0.9308 - loss: 0.3553 - val_accuracy: 0.4623 - val_loss: 2.9176 - learning_rate: 1.0000e-04\n",
      "Epoch 7/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 242ms/step - accuracy: 0.9401 - loss: 0.3048 - val_accuracy: 0.4824 - val_loss: 2.9919 - learning_rate: 1.0000e-04\n",
      "Epoch 8/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 240ms/step - accuracy: 0.9619 - loss: 0.2291 - val_accuracy: 0.4874 - val_loss: 3.0659 - learning_rate: 1.0000e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 237ms/step - accuracy: 0.9633 - loss: 0.2206 - val_accuracy: 0.4925 - val_loss: 3.0762 - learning_rate: 2.0000e-05\n",
      "Epoch 10/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 237ms/step - accuracy: 0.9633 - loss: 0.2307 - val_accuracy: 0.4975 - val_loss: 3.0834 - learning_rate: 2.0000e-05\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - accuracy: 0.4936 - loss: 2.6154\n",
      "Test accuracy: 0.47236180305480957\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras import layers, models\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define paths\n",
    "train_dir = 'dataset/train'\n",
    "test_dir = 'dataset/test'\n",
    "\n",
    "# Load datasets\n",
    "batch_size = 32\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "\n",
    "train_dataset = image_dataset_from_directory(train_dir,\n",
    "                                             shuffle=True,\n",
    "                                             batch_size=batch_size,\n",
    "                                             image_size=(img_height, img_width))\n",
    "\n",
    "test_dataset = image_dataset_from_directory(test_dir,\n",
    "                                            shuffle=True,\n",
    "                                            batch_size=batch_size,\n",
    "                                            image_size=(img_height, img_width))\n",
    "\n",
    "# Data augmentation\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip('horizontal'),\n",
    "    layers.RandomRotation(0.2),\n",
    "    layers.RandomZoom(0.2),\n",
    "])\n",
    "\n",
    "# Normalize the images to the range the pre-trained model expects\n",
    "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "\n",
    "# Create the base model from the pre-trained model MobileNet V2\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=(img_height, img_width, 3),\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "\n",
    "# Unfreeze some layers of the base model for fine-tuning\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-20]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add classification head\n",
    "num_classes = len(train_dataset.class_names)\n",
    "\n",
    "model = models.Sequential([\n",
    "    data_augmentation,\n",
    "    layers.Lambda(preprocess_input),\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Callbacks for early stopping and model checkpoint\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "# model_checkpoint = tf.keras.callbacks.ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_loss')\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.00001)\n",
    "\n",
    "# Train the model\n",
    "epochs = 10\n",
    "history = model.fit(train_dataset,\n",
    "                    validation_data=test_dataset,\n",
    "                    epochs=epochs,\n",
    "                    callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "# Load the best model\n",
    "# model.load_weights('best_model.h5')\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(test_dataset)\n",
    "print(f'Test accuracy: {accuracy}')\n",
    "\n",
    "# Convert the model to TFLite\n",
    "# converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "# tflite_model = converter.convert()\n",
    "\n",
    "# # Save the model\n",
    "# with open('model_david.tflite', 'wb') as f:\n",
    "#     f.write(tflite_model)\n",
    "\n",
    "# print(\"Model converted to TFLite and saved as 'model.tflite'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 793 files belonging to 20 classes.\n",
      "Found 199 files belonging to 20 classes.\n",
      "Epoch 1/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 406ms/step - accuracy: 0.2571 - loss: 2.5605 - val_accuracy: 0.4824 - val_loss: 2.6670 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 320ms/step - accuracy: 0.8246 - loss: 0.6559 - val_accuracy: 0.5829 - val_loss: 3.7654 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 311ms/step - accuracy: 0.8961 - loss: 0.2813 - val_accuracy: 0.5477 - val_loss: 4.5148 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 331ms/step - accuracy: 0.9393 - loss: 0.2023 - val_accuracy: 0.6080 - val_loss: 4.7385 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 326ms/step - accuracy: 0.9636 - loss: 0.1214 - val_accuracy: 0.6131 - val_loss: 4.6073 - learning_rate: 2.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 351ms/step - accuracy: 0.9800 - loss: 0.0736 - val_accuracy: 0.6181 - val_loss: 4.5141 - learning_rate: 2.0000e-04\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 251ms/step - accuracy: 0.4824 - loss: 2.6281\n",
      "Test accuracy: 0.48241207003593445\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "# Define paths\n",
    "train_dir = 'dataset/train'\n",
    "test_dir = 'dataset/test'\n",
    "\n",
    "# Load datasets\n",
    "batch_size = 32\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_height, img_width)\n",
    ")\n",
    "\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_height, img_width)\n",
    ")\n",
    "\n",
    "# Retrieve class names\n",
    "class_names = train_dataset.class_names\n",
    "\n",
    "# Prefetch the data for optimal performance\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# Simplified data augmentation\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip('horizontal'),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "])\n",
    "\n",
    "# Normalize the images to the range the pre-trained model expects\n",
    "preprocess_input = tf.keras.applications.efficientnet.preprocess_input\n",
    "\n",
    "# Create the base model from the pre-trained EfficientNetB0\n",
    "base_model = tf.keras.applications.EfficientNetB0(\n",
    "    input_shape=(img_height, img_width, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "# Unfreeze some layers of the base model for fine-tuning\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-20]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Define the number of classes\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# Create the model\n",
    "model = models.Sequential([\n",
    "    data_augmentation,\n",
    "    layers.Lambda(preprocess_input),\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Define callbacks for early stopping and learning rate reduction\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.00001)\n",
    "\n",
    "# Learning rate scheduler\n",
    "# def scheduler(epoch, lr):\n",
    "#     if epoch < 5:\n",
    "#         return lr\n",
    "#     else:\n",
    "#         return lr * tf.math.exp(-0.1)\n",
    "\n",
    "# lr_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "# Train the model\n",
    "epochs = 30  # Keeping a higher number of epochs with early stopping\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=test_dataset,\n",
    "    epochs=epochs,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(test_dataset)\n",
    "print(f'Test accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 793 files belonging to 20 classes.\n",
      "Found 199 files belonging to 20 classes.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m83683744/83683744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 1us/step\n",
      "Epoch 1/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 1s/step - accuracy: 0.0908 - loss: 2.9339 - val_accuracy: 0.2111 - val_loss: 2.6871 - learning_rate: 1.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1s/step - accuracy: 0.3662 - loss: 2.4441 - val_accuracy: 0.3869 - val_loss: 2.2846 - learning_rate: 1.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2s/step - accuracy: 0.6278 - loss: 1.7962 - val_accuracy: 0.5276 - val_loss: 2.0170 - learning_rate: 1.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 2s/step - accuracy: 0.7674 - loss: 1.1543 - val_accuracy: 0.5477 - val_loss: 2.2330 - learning_rate: 1.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.8492 - loss: 0.7371 - val_accuracy: 0.5528 - val_loss: 2.7471 - learning_rate: 1.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.8996 - loss: 0.4881 - val_accuracy: 0.5729 - val_loss: 3.0145 - learning_rate: 1.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2s/step - accuracy: 0.8990 - loss: 0.4100 - val_accuracy: 0.5678 - val_loss: 3.0826 - learning_rate: 2.0000e-05\n",
      "Epoch 8/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1s/step - accuracy: 0.9228 - loss: 0.3319 - val_accuracy: 0.5729 - val_loss: 3.0541 - learning_rate: 2.0000e-05\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 666ms/step - accuracy: 0.5261 - loss: 2.0332\n",
      "Test accuracy: 0.5276381969451904\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "# Define paths\n",
    "train_dir = 'dataset/train'\n",
    "test_dir = 'dataset/test'\n",
    "\n",
    "# Load datasets\n",
    "batch_size = 32\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_height, img_width)\n",
    ")\n",
    "\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_height, img_width)\n",
    ")\n",
    "\n",
    "# Retrieve class names\n",
    "class_names = train_dataset.class_names\n",
    "\n",
    "# Prefetch the data for optimal performance\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# Data augmentation\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip('horizontal'),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "])\n",
    "\n",
    "base_model = tf.keras.applications.Xception(\n",
    "    input_shape=(img_height, img_width, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "preprocess_input = tf.keras.applications.xception.preprocess_input\n",
    "\n",
    "# Unfreeze some layers of the base model for fine-tuning\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-20]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Define the number of classes\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# Create the model\n",
    "model = models.Sequential([\n",
    "    data_augmentation,\n",
    "    layers.Lambda(preprocess_input),\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Define callbacks for early stopping and learning rate reduction\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.00001)\n",
    "\n",
    "# Train the model\n",
    "epochs = 30  # Increased number of epochs with early stopping\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=test_dataset,\n",
    "    epochs=epochs,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(test_dataset)\n",
    "print(f'Test accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 793 files belonging to 20 classes.\n",
      "Found 199 files belonging to 20 classes.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/nasnet/NASNet-mobile-no-top.h5\n",
      "\u001b[1m19993432/19993432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1us/step\n",
      "Epoch 1/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 399ms/step - accuracy: 0.0670 - loss: 3.1310 - val_accuracy: 0.2161 - val_loss: 2.7786 - learning_rate: 1.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - accuracy: 0.2063 - loss: 2.6747 - val_accuracy: 0.3467 - val_loss: 2.5954 - learning_rate: 1.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - accuracy: 0.3395 - loss: 2.4005 - val_accuracy: 0.3618 - val_loss: 2.4528 - learning_rate: 1.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - accuracy: 0.4362 - loss: 2.1143 - val_accuracy: 0.3869 - val_loss: 2.3408 - learning_rate: 1.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 235ms/step - accuracy: 0.4835 - loss: 1.9560 - val_accuracy: 0.4171 - val_loss: 2.2589 - learning_rate: 1.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 267ms/step - accuracy: 0.5264 - loss: 1.6863 - val_accuracy: 0.4322 - val_loss: 2.2006 - learning_rate: 1.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 269ms/step - accuracy: 0.5710 - loss: 1.5687 - val_accuracy: 0.4422 - val_loss: 2.1837 - learning_rate: 1.0000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 269ms/step - accuracy: 0.6114 - loss: 1.4459 - val_accuracy: 0.4472 - val_loss: 2.1733 - learning_rate: 1.0000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 275ms/step - accuracy: 0.6259 - loss: 1.3492 - val_accuracy: 0.4874 - val_loss: 2.1995 - learning_rate: 1.0000e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 311ms/step - accuracy: 0.6832 - loss: 1.1367 - val_accuracy: 0.4623 - val_loss: 2.2105 - learning_rate: 1.0000e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 335ms/step - accuracy: 0.6814 - loss: 1.1260 - val_accuracy: 0.4874 - val_loss: 2.2229 - learning_rate: 1.0000e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 336ms/step - accuracy: 0.7227 - loss: 1.0334 - val_accuracy: 0.4824 - val_loss: 2.2189 - learning_rate: 2.0000e-05\n",
      "Epoch 13/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 333ms/step - accuracy: 0.7309 - loss: 1.0113 - val_accuracy: 0.4874 - val_loss: 2.2245 - learning_rate: 2.0000e-05\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 211ms/step - accuracy: 0.4555 - loss: 2.1339\n",
      "Test accuracy: 0.44723618030548096\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "# Define paths\n",
    "train_dir = 'dataset/train'\n",
    "test_dir = 'dataset/test'\n",
    "\n",
    "# Load datasets\n",
    "batch_size = 32\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_height, img_width)\n",
    ")\n",
    "\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_height, img_width)\n",
    ")\n",
    "\n",
    "# Retrieve class names\n",
    "class_names = train_dataset.class_names\n",
    "\n",
    "# Prefetch the data for optimal performance\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# Data augmentation\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip('horizontal'),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "])\n",
    "\n",
    "base_model = tf.keras.applications.NASNetMobile(\n",
    "    input_shape=(img_height, img_width, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "preprocess_input = tf.keras.applications.nasnet.preprocess_input\n",
    "\n",
    "# Unfreeze some layers of the base model for fine-tuning\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-20]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Define the number of classes\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# Create the model\n",
    "model = models.Sequential([\n",
    "    data_augmentation,\n",
    "    layers.Lambda(preprocess_input),\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Define callbacks for early stopping and learning rate reduction\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.00001)\n",
    "\n",
    "# Train the model\n",
    "epochs = 30  # Increased number of epochs with early stopping\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=test_dataset,\n",
    "    epochs=epochs,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(test_dataset)\n",
    "print(f'Test accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 793 files belonging to 20 classes.\n",
      "Found 199 files belonging to 20 classes.\n",
      "Epoch 1/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 399ms/step - accuracy: 0.0614 - loss: 4.4166 - val_accuracy: 0.1357 - val_loss: 2.8538 - learning_rate: 1.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 329ms/step - accuracy: 0.0956 - loss: 3.8067 - val_accuracy: 0.2613 - val_loss: 2.7184 - learning_rate: 1.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 354ms/step - accuracy: 0.1627 - loss: 3.3403 - val_accuracy: 0.3417 - val_loss: 2.5819 - learning_rate: 1.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 414ms/step - accuracy: 0.2265 - loss: 2.8671 - val_accuracy: 0.3668 - val_loss: 2.4538 - learning_rate: 1.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 471ms/step - accuracy: 0.2850 - loss: 2.5530 - val_accuracy: 0.4221 - val_loss: 2.3343 - learning_rate: 1.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 459ms/step - accuracy: 0.3972 - loss: 2.0856 - val_accuracy: 0.4322 - val_loss: 2.2426 - learning_rate: 1.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 391ms/step - accuracy: 0.4319 - loss: 1.9697 - val_accuracy: 0.4925 - val_loss: 2.1619 - learning_rate: 1.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 458ms/step - accuracy: 0.5027 - loss: 1.6779 - val_accuracy: 0.5025 - val_loss: 2.1209 - learning_rate: 1.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 465ms/step - accuracy: 0.4774 - loss: 1.7135 - val_accuracy: 0.5126 - val_loss: 2.1095 - learning_rate: 1.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 458ms/step - accuracy: 0.5433 - loss: 1.4518 - val_accuracy: 0.5176 - val_loss: 2.1364 - learning_rate: 1.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 456ms/step - accuracy: 0.5829 - loss: 1.3973 - val_accuracy: 0.5377 - val_loss: 2.1735 - learning_rate: 1.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 461ms/step - accuracy: 0.6412 - loss: 1.2321 - val_accuracy: 0.5377 - val_loss: 2.2368 - learning_rate: 1.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 465ms/step - accuracy: 0.6557 - loss: 1.1907 - val_accuracy: 0.5377 - val_loss: 2.2744 - learning_rate: 2.0000e-05\n",
      "Epoch 14/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 423ms/step - accuracy: 0.6404 - loss: 1.0910 - val_accuracy: 0.5377 - val_loss: 2.3154 - learning_rate: 2.0000e-05\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - accuracy: 0.5175 - loss: 2.0500\n",
      "Test accuracy: 0.5125628113746643\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "# Define paths\n",
    "train_dir = 'dataset/train'\n",
    "test_dir = 'dataset/test'\n",
    "\n",
    "# Load datasets\n",
    "batch_size = 32\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_height, img_width)\n",
    ")\n",
    "\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_height, img_width)\n",
    ")\n",
    "\n",
    "# Retrieve class names\n",
    "class_names = train_dataset.class_names\n",
    "\n",
    "# Prefetch the data for optimal performance\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# Data augmentation\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip('horizontal'),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "])\n",
    "\n",
    "# Normalize the images to the range the pre-trained model expects\n",
    "preprocess_input = tf.keras.applications.efficientnet.preprocess_input\n",
    "\n",
    "# Create the base model from the pre-trained EfficientNetB0\n",
    "base_model = tf.keras.applications.EfficientNetB0(\n",
    "    input_shape=(img_height, img_width, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "# Unfreeze some layers of the base model for fine-tuning\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-20]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Define the number of classes\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# Create the model\n",
    "model = models.Sequential([\n",
    "    data_augmentation,\n",
    "    layers.Lambda(preprocess_input),\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Define callbacks for early stopping and learning rate reduction\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.00001)\n",
    "\n",
    "# Train the model\n",
    "epochs = 50  # Increased number of epochs with early stopping\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=test_dataset,\n",
    "    epochs=epochs,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(test_dataset)\n",
    "print(f'Test accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 793 files belonging to 20 classes.\n",
      "Found 199 files belonging to 20 classes.\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:From c:\\Users\\david\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:184: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 1s/step - accuracy: 0.0516 - loss: 4.4376 - val_accuracy: 0.1156 - val_loss: 2.9500 - learning_rate: 1.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.1087 - loss: 3.7369 - val_accuracy: 0.2060 - val_loss: 2.8411 - learning_rate: 1.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.1858 - loss: 3.0817 - val_accuracy: 0.2563 - val_loss: 2.6983 - learning_rate: 1.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.2835 - loss: 2.6071 - val_accuracy: 0.3467 - val_loss: 2.5447 - learning_rate: 1.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1s/step - accuracy: 0.4404 - loss: 2.0342 - val_accuracy: 0.4271 - val_loss: 2.3678 - learning_rate: 1.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1s/step - accuracy: 0.5059 - loss: 1.7096 - val_accuracy: 0.4724 - val_loss: 2.2190 - learning_rate: 1.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1s/step - accuracy: 0.5315 - loss: 1.5741 - val_accuracy: 0.4975 - val_loss: 2.1125 - learning_rate: 1.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.6078 - loss: 1.2423 - val_accuracy: 0.5377 - val_loss: 2.0702 - learning_rate: 1.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.6543 - loss: 1.1158 - val_accuracy: 0.5578 - val_loss: 2.0952 - learning_rate: 1.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1s/step - accuracy: 0.6754 - loss: 0.9499 - val_accuracy: 0.5678 - val_loss: 2.1583 - learning_rate: 1.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.7115 - loss: 0.8887 - val_accuracy: 0.5779 - val_loss: 2.2582 - learning_rate: 1.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.7762 - loss: 0.7061 - val_accuracy: 0.5930 - val_loss: 2.3182 - learning_rate: 2.0000e-05\n",
      "Epoch 13/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - accuracy: 0.7525 - loss: 0.8266 - val_accuracy: 0.6080 - val_loss: 2.3822 - learning_rate: 2.0000e-05\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 681ms/step - accuracy: 0.5241 - loss: 2.0594\n",
      "Test accuracy: 0.5376884341239929\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "# Define paths\n",
    "train_dir = 'dataset/train'\n",
    "test_dir = 'dataset/test'\n",
    "\n",
    "# Load datasets\n",
    "batch_size = 32\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_height, img_width)\n",
    ")\n",
    "\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_height, img_width)\n",
    ")\n",
    "\n",
    "# Retrieve class names\n",
    "class_names = train_dataset.class_names\n",
    "\n",
    "# Prefetch the data for optimal performance\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# Enhanced data augmentation\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip('horizontal'),\n",
    "    layers.RandomRotation(0.2),\n",
    "    layers.RandomZoom(0.2),\n",
    "    layers.RandomContrast(0.2),\n",
    "    layers.RandomBrightness(0.2),\n",
    "])\n",
    "\n",
    "# Normalize the images to the range the pre-trained model expects\n",
    "preprocess_input = tf.keras.applications.efficientnet.preprocess_input\n",
    "\n",
    "# Create the base model from the pre-trained EfficientNetB4\n",
    "base_model = tf.keras.applications.EfficientNetB4(\n",
    "    input_shape=(img_height, img_width, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "# Unfreeze more layers of the base model for fine-tuning\n",
    "base_model.trainable = True\n",
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = 300\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Define the number of classes\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# Create the model\n",
    "model = models.Sequential([\n",
    "    data_augmentation,\n",
    "    layers.Lambda(preprocess_input),\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Define callbacks for early stopping, learning rate reduction, and learning rate scheduling\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.00001)\n",
    "\n",
    "# Train the model\n",
    "epochs = 50  # Increased number of epochs with early stopping\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=test_dataset,\n",
    "    epochs=epochs,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(test_dataset)\n",
    "print(f'Test accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 793 files belonging to 20 classes.\n",
      "Found 199 files belonging to 20 classes.\n",
      "Epoch 1/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 5s/step - accuracy: 0.0729 - loss: 5.0828 - val_accuracy: 0.1357 - val_loss: 3.6326 - learning_rate: 1.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 5s/step - accuracy: 0.1528 - loss: 4.2388 - val_accuracy: 0.2010 - val_loss: 3.4719 - learning_rate: 1.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 5s/step - accuracy: 0.2308 - loss: 3.5996 - val_accuracy: 0.3467 - val_loss: 3.2548 - learning_rate: 1.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 4s/step - accuracy: 0.4087 - loss: 2.8289 - val_accuracy: 0.3920 - val_loss: 3.0287 - learning_rate: 1.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 4s/step - accuracy: 0.5771 - loss: 2.2169 - val_accuracy: 0.4673 - val_loss: 2.8482 - learning_rate: 1.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 5s/step - accuracy: 0.6629 - loss: 1.8437 - val_accuracy: 0.4724 - val_loss: 2.7561 - learning_rate: 1.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 5s/step - accuracy: 0.7281 - loss: 1.5965 - val_accuracy: 0.5578 - val_loss: 2.7628 - learning_rate: 1.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 6s/step - accuracy: 0.7659 - loss: 1.4841 - val_accuracy: 0.5276 - val_loss: 2.7917 - learning_rate: 1.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 6s/step - accuracy: 0.8121 - loss: 1.3027 - val_accuracy: 0.5477 - val_loss: 2.8964 - learning_rate: 1.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 6s/step - accuracy: 0.8432 - loss: 1.1920 - val_accuracy: 0.5628 - val_loss: 2.9504 - learning_rate: 2.0000e-05\n",
      "Epoch 11/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 6s/step - accuracy: 0.8529 - loss: 1.1821 - val_accuracy: 0.5628 - val_loss: 3.0896 - learning_rate: 2.0000e-05\n",
      "Epoch 12/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 5s/step - accuracy: 0.8575 - loss: 1.1324 - val_accuracy: 0.5477 - val_loss: 3.1807 - learning_rate: 2.0000e-05\n",
      "Epoch 13/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 4s/step - accuracy: 0.8778 - loss: 1.1354 - val_accuracy: 0.5427 - val_loss: 3.2924 - learning_rate: 1.0000e-05\n",
      "Epoch 14/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 4s/step - accuracy: 0.8624 - loss: 1.1510 - val_accuracy: 0.5628 - val_loss: 3.4140 - learning_rate: 1.0000e-05\n",
      "Epoch 15/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 6s/step - accuracy: 0.8607 - loss: 1.1793 - val_accuracy: 0.5628 - val_loss: 3.5571 - learning_rate: 1.0000e-05\n",
      "Epoch 16/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 6s/step - accuracy: 0.8868 - loss: 1.0762 - val_accuracy: 0.5427 - val_loss: 3.6262 - learning_rate: 1.0000e-05\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.4727 - loss: 2.7463\n",
      "Test accuracy: 0.47236180305480957\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "# Define paths\n",
    "train_dir = 'dataset/train'\n",
    "test_dir = 'dataset/test'\n",
    "\n",
    "# Load datasets\n",
    "batch_size = 32\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_height, img_width)\n",
    ")\n",
    "\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_height, img_width)\n",
    ")\n",
    "\n",
    "# Retrieve class names\n",
    "class_names = train_dataset.class_names\n",
    "\n",
    "# Prefetch the data for optimal performance\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# Enhanced data augmentation\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip('horizontal'),\n",
    "    layers.RandomRotation(0.2),\n",
    "    layers.RandomZoom(0.2),\n",
    "    layers.RandomContrast(0.2),\n",
    "    layers.RandomBrightness(0.2),\n",
    "])\n",
    "\n",
    "# Normalize the images to the range the pre-trained model expects\n",
    "preprocess_input = tf.keras.applications.efficientnet.preprocess_input\n",
    "\n",
    "# Create the base model from the pre-trained EfficientNetB4\n",
    "base_model = tf.keras.applications.EfficientNetV2M(\n",
    "    input_shape=(img_height, img_width, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "# Unfreeze more layers of the base model for fine-tuning\n",
    "base_model.trainable = True\n",
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = 200\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Define the number of classes\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# Create the model\n",
    "model = models.Sequential([\n",
    "    data_augmentation,\n",
    "    layers.Lambda(preprocess_input),\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Define callbacks for early stopping, learning rate reduction, and learning rate scheduling\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.00001)\n",
    "\n",
    "# Train the model\n",
    "epochs = 50\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=test_dataset,\n",
    "    epochs=epochs,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(test_dataset)\n",
    "print(f'Test accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 793 files belonging to 20 classes.\n",
      "Found 199 files belonging to 20 classes.\n",
      "Epoch 1/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 2s/step - accuracy: 0.0607 - loss: 5.3127 - val_accuracy: 0.1106 - val_loss: 3.7266 - learning_rate: 1.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.0991 - loss: 4.6848 - val_accuracy: 0.2060 - val_loss: 3.6143 - learning_rate: 1.1220e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.1710 - loss: 3.9027 - val_accuracy: 0.2613 - val_loss: 3.4739 - learning_rate: 1.2589e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 0.2843 - loss: 3.4032 - val_accuracy: 0.3266 - val_loss: 3.2984 - learning_rate: 1.4125e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 0.4377 - loss: 2.7295 - val_accuracy: 0.3920 - val_loss: 3.0891 - learning_rate: 1.5849e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 0.5036 - loss: 2.4389 - val_accuracy: 0.4422 - val_loss: 2.8982 - learning_rate: 1.7783e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.6295 - loss: 1.9674 - val_accuracy: 0.4573 - val_loss: 2.8435 - learning_rate: 1.9953e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 0.7068 - loss: 1.7085 - val_accuracy: 0.4874 - val_loss: 2.8957 - learning_rate: 2.2387e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 0.7874 - loss: 1.4891 - val_accuracy: 0.5126 - val_loss: 3.0090 - learning_rate: 2.5119e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 0.8515 - loss: 1.3248 - val_accuracy: 0.5477 - val_loss: 3.1634 - learning_rate: 5.6368e-05\n",
      "Epoch 11/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.8718 - loss: 1.2235 - val_accuracy: 0.5628 - val_loss: 3.3856 - learning_rate: 3.1623e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 0.8816 - loss: 1.1659 - val_accuracy: 0.5477 - val_loss: 3.5230 - learning_rate: 3.5481e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.9191 - loss: 1.0412 - val_accuracy: 0.5829 - val_loss: 3.7335 - learning_rate: 7.9621e-05\n",
      "Epoch 14/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.9385 - loss: 0.9889 - val_accuracy: 0.5930 - val_loss: 4.0104 - learning_rate: 4.4668e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.9462 - loss: 0.9408 - val_accuracy: 0.5678 - val_loss: 4.4074 - learning_rate: 5.0119e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 0.9401 - loss: 0.9646 - val_accuracy: 0.5729 - val_loss: 4.4807 - learning_rate: 1.1247e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 0.9558 - loss: 0.8999 - val_accuracy: 0.5729 - val_loss: 4.3504 - learning_rate: 6.3096e-04\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 688ms/step - accuracy: 0.4684 - loss: 2.8108\n",
      "Test accuracy: 0.45728641748428345\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "# Define paths\n",
    "train_dir = 'dataset/train'\n",
    "test_dir = 'dataset/test'\n",
    "\n",
    "# Load datasets\n",
    "batch_size = 32\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_height, img_width)\n",
    ")\n",
    "\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_height, img_width)\n",
    ")\n",
    "\n",
    "# Retrieve class names\n",
    "class_names = train_dataset.class_names\n",
    "\n",
    "# Prefetch the data for optimal performance\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# Enhanced data augmentation\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip('horizontal'),\n",
    "    layers.RandomRotation(0.2),\n",
    "    layers.RandomZoom(0.2),\n",
    "    layers.RandomContrast(0.2),\n",
    "    layers.RandomBrightness(0.2),\n",
    "    layers.RandomTranslation(0.1, 0.1),\n",
    "])\n",
    "\n",
    "# Normalize the images to the range the pre-trained model expects\n",
    "preprocess_input = tf.keras.applications.efficientnet.preprocess_input\n",
    "\n",
    "# Create the base model from the pre-trained EfficientNetB4\n",
    "base_model = tf.keras.applications.EfficientNetB4(\n",
    "    input_shape=(img_height, img_width, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "# Unfreeze more layers of the base model for fine-tuning\n",
    "base_model.trainable = True\n",
    "fine_tune_at = 200\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Define the number of classes\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# Create the model\n",
    "model = models.Sequential([\n",
    "    data_augmentation,\n",
    "    layers.Lambda(preprocess_input),\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Define callbacks\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.00001)\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-4 * 10 ** (epoch / 20))\n",
    "\n",
    "# Train the model\n",
    "epochs = 50\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=test_dataset,\n",
    "    epochs=epochs,\n",
    "    callbacks=[early_stopping, reduce_lr, lr_scheduler]\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(test_dataset)\n",
    "print(f'Test accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 793 files belonging to 20 classes.\n",
      "Found 199 files belonging to 20 classes.\n",
      "Epoch 1/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 2s/step - accuracy: 0.0696 - loss: 12.7296 - val_accuracy: 0.0553 - val_loss: 10.9226 - learning_rate: 1.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 2s/step - accuracy: 0.0813 - loss: 12.2936 - val_accuracy: 0.0603 - val_loss: 10.8242 - learning_rate: 1.1220e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.0723 - loss: 11.9696 - val_accuracy: 0.1106 - val_loss: 10.6929 - learning_rate: 1.2589e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.1465 - loss: 11.5832 - val_accuracy: 0.2060 - val_loss: 10.4909 - learning_rate: 1.4125e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 0.2056 - loss: 10.9186 - val_accuracy: 0.2965 - val_loss: 10.2208 - learning_rate: 1.5849e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.2877 - loss: 10.4467 - val_accuracy: 0.3970 - val_loss: 9.8717 - learning_rate: 1.7783e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.3694 - loss: 10.0028 - val_accuracy: 0.4422 - val_loss: 9.6392 - learning_rate: 1.9953e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.4271 - loss: 9.5812 - val_accuracy: 0.4472 - val_loss: 9.5130 - learning_rate: 2.2387e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 0.5094 - loss: 9.1278 - val_accuracy: 0.4724 - val_loss: 9.4694 - learning_rate: 2.5119e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.5998 - loss: 8.6279 - val_accuracy: 0.4925 - val_loss: 9.6271 - learning_rate: 2.8184e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.6915 - loss: 8.2003 - val_accuracy: 0.5226 - val_loss: 9.8070 - learning_rate: 3.1623e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.7306 - loss: 7.8930 - val_accuracy: 0.5226 - val_loss: 9.8780 - learning_rate: 7.0963e-05\n",
      "Epoch 13/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.7848 - loss: 7.5551 - val_accuracy: 0.5477 - val_loss: 9.9499 - learning_rate: 3.9811e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.8350 - loss: 7.3017 - val_accuracy: 0.5327 - val_loss: 9.9998 - learning_rate: 4.4668e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.8423 - loss: 7.0258 - val_accuracy: 0.5377 - val_loss: 10.0340 - learning_rate: 1.0024e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.8647 - loss: 6.6642 - val_accuracy: 0.5578 - val_loss: 9.8801 - learning_rate: 5.6234e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.8937 - loss: 6.3365 - val_accuracy: 0.5377 - val_loss: 9.8275 - learning_rate: 6.3096e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.8764 - loss: 6.0838 - val_accuracy: 0.5578 - val_loss: 9.5720 - learning_rate: 1.4159e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.9260 - loss: 5.6830 - val_accuracy: 0.5427 - val_loss: 9.9628 - learning_rate: 7.9433e-04\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 665ms/step - accuracy: 0.4489 - loss: 9.4133\n",
      "Test accuracy: 0.47236180305480957\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "# Define paths\n",
    "train_dir = 'dataset/train'\n",
    "test_dir = 'dataset/test'\n",
    "\n",
    "# Load datasets\n",
    "batch_size = 32\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_height, img_width)\n",
    ")\n",
    "\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_height, img_width)\n",
    ")\n",
    "\n",
    "# Retrieve class names\n",
    "class_names = train_dataset.class_names\n",
    "\n",
    "# Prefetch the data for optimal performance\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# Enhanced data augmentation\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip('horizontal'),\n",
    "    layers.RandomRotation(0.3),\n",
    "    layers.RandomZoom(0.3),\n",
    "    layers.RandomContrast(0.3),\n",
    "    layers.RandomBrightness(0.3),\n",
    "    layers.RandomTranslation(0.2, 0.2),\n",
    "])\n",
    "\n",
    "# Normalize the images to the range the pre-trained model expects\n",
    "preprocess_input = tf.keras.applications.efficientnet.preprocess_input\n",
    "\n",
    "# Create the base model from the pre-trained EfficientNetB4\n",
    "base_model = tf.keras.applications.EfficientNetB4(\n",
    "    input_shape=(img_height, img_width, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "# Unfreeze more layers of the base model for fine-tuning\n",
    "base_model.trainable = True\n",
    "fine_tune_at = 200\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Define the number of classes\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# Create the model\n",
    "model = models.Sequential([\n",
    "    data_augmentation,\n",
    "    layers.Lambda(preprocess_input),\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.6),\n",
    "    layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.6),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Define callbacks\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.00001)\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-4 * 10 ** (epoch / 20))\n",
    "\n",
    "# Train the model\n",
    "epochs = 50\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=test_dataset,\n",
    "    epochs=epochs,\n",
    "    callbacks=[early_stopping, reduce_lr, lr_scheduler]\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(test_dataset)\n",
    "print(f'Test accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
