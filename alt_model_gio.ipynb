{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IztOZxKiFX-",
        "outputId": "6d052eae-65fa-4b3a-e328-e6542167f211"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'machine-learning'...\n",
            "remote: Enumerating objects: 1000, done.\u001b[K\n",
            "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 1000 (delta 13), reused 2 (delta 2), pack-reused 982\u001b[K\n",
            "Receiving objects: 100% (1000/1000), 35.63 MiB | 33.05 MiB/s, done.\n",
            "Resolving deltas: 100% (70/70), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Dapur-Nusantara-Bangkit-2024-Batch-2/machine-learning.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from tensorflow.keras import layers, models\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Define paths\n",
        "train_dir = '/content/machine-learning/dataset/train'\n",
        "test_dir = '/content/machine-learning/dataset/test'\n",
        "\n",
        "# Load datasets\n",
        "batch_size = 32\n",
        "img_height = 224\n",
        "img_width = 224\n",
        "\n",
        "train_dataset = image_dataset_from_directory(train_dir,\n",
        "                                             shuffle=True,\n",
        "                                             batch_size=batch_size,\n",
        "                                             image_size=(img_height, img_width))\n",
        "\n",
        "test_dataset = image_dataset_from_directory(test_dir,\n",
        "                                            shuffle=True,\n",
        "                                            batch_size=batch_size,\n",
        "                                            image_size=(img_height, img_width))\n",
        "\n",
        "# Data augmentation\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.RandomFlip('horizontal'),\n",
        "    layers.RandomRotation(0.2),\n",
        "    layers.RandomZoom(0.2),\n",
        "])\n",
        "\n",
        "# Normalize the images to the range the pre-trained model expects\n",
        "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
        "\n",
        "# Create the base model from the pre-trained model MobileNet V2\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=(img_height, img_width, 3),\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')\n",
        "\n",
        "# Unfreeze some layers of the base model for fine-tuning\n",
        "base_model.trainable = True\n",
        "for layer in base_model.layers[:-20]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add classification head\n",
        "num_classes = len(train_dataset.class_names)\n",
        "\n",
        "model = models.Sequential([\n",
        "    data_augmentation,\n",
        "    layers.Lambda(preprocess_input),\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Callbacks for early stopping and model checkpoint\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "model_checkpoint = tf.keras.callbacks.ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_loss')\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.00001)\n",
        "\n",
        "# Train the model\n",
        "epochs = 20\n",
        "history = model.fit(train_dataset,\n",
        "                    validation_data=test_dataset,\n",
        "                    epochs=epochs,\n",
        "                    callbacks=[early_stopping, model_checkpoint, reduce_lr])\n",
        "\n",
        "# Load the best model\n",
        "model.load_weights('best_model.h5')\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(test_dataset)\n",
        "print(f'Test accuracy: {accuracy}')\n",
        "\n",
        "# Convert the model to TFLite\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model\n",
        "with open('model.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "print(\"Model converted to TFLite and saved as 'model.tflite'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sNoDJ1GjKkh",
        "outputId": "991c4e84-45b8-49dc-e0be-8309446ffd12"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 673 files belonging to 17 classes.\n",
            "Found 169 files belonging to 17 classes.\n",
            "Epoch 1/20\n",
            "22/22 [==============================] - 93s 3s/step - loss: 2.4597 - accuracy: 0.2779 - val_loss: 2.1655 - val_accuracy: 0.3195 - lr: 1.0000e-04\n",
            "Epoch 2/20\n",
            "22/22 [==============================] - 49s 2s/step - loss: 1.3432 - accuracy: 0.6761 - val_loss: 1.5587 - val_accuracy: 0.4852 - lr: 1.0000e-04\n",
            "Epoch 3/20\n",
            "22/22 [==============================] - 52s 2s/step - loss: 0.8521 - accuracy: 0.8232 - val_loss: 1.2891 - val_accuracy: 0.5444 - lr: 1.0000e-04\n",
            "Epoch 4/20\n",
            "22/22 [==============================] - 52s 2s/step - loss: 0.6029 - accuracy: 0.8945 - val_loss: 1.0477 - val_accuracy: 0.6213 - lr: 1.0000e-04\n",
            "Epoch 5/20\n",
            "22/22 [==============================] - 53s 2s/step - loss: 0.4564 - accuracy: 0.9198 - val_loss: 0.8919 - val_accuracy: 0.6805 - lr: 1.0000e-04\n",
            "Epoch 6/20\n",
            "22/22 [==============================] - 53s 2s/step - loss: 0.3475 - accuracy: 0.9450 - val_loss: 0.8169 - val_accuracy: 0.6982 - lr: 1.0000e-04\n",
            "Epoch 7/20\n",
            "22/22 [==============================] - 49s 2s/step - loss: 0.3019 - accuracy: 0.9376 - val_loss: 0.7426 - val_accuracy: 0.7337 - lr: 1.0000e-04\n",
            "Epoch 8/20\n",
            "22/22 [==============================] - 51s 2s/step - loss: 0.2375 - accuracy: 0.9658 - val_loss: 0.7095 - val_accuracy: 0.7456 - lr: 1.0000e-04\n",
            "Epoch 9/20\n",
            "22/22 [==============================] - 50s 2s/step - loss: 0.2103 - accuracy: 0.9703 - val_loss: 0.6903 - val_accuracy: 0.7456 - lr: 1.0000e-04\n",
            "Epoch 10/20\n",
            "22/22 [==============================] - 52s 2s/step - loss: 0.1905 - accuracy: 0.9792 - val_loss: 0.6755 - val_accuracy: 0.7692 - lr: 1.0000e-04\n",
            "Epoch 11/20\n",
            "22/22 [==============================] - 49s 2s/step - loss: 0.1655 - accuracy: 0.9807 - val_loss: 0.7203 - val_accuracy: 0.7574 - lr: 1.0000e-04\n",
            "Epoch 12/20\n",
            "22/22 [==============================] - 53s 2s/step - loss: 0.1685 - accuracy: 0.9718 - val_loss: 0.6434 - val_accuracy: 0.7811 - lr: 1.0000e-04\n",
            "Epoch 13/20\n",
            "22/22 [==============================] - 50s 2s/step - loss: 0.1434 - accuracy: 0.9733 - val_loss: 0.6280 - val_accuracy: 0.7929 - lr: 1.0000e-04\n",
            "Epoch 14/20\n",
            "22/22 [==============================] - 49s 2s/step - loss: 0.1264 - accuracy: 0.9822 - val_loss: 0.6040 - val_accuracy: 0.8047 - lr: 1.0000e-04\n",
            "Epoch 15/20\n",
            "22/22 [==============================] - 51s 2s/step - loss: 0.0980 - accuracy: 0.9926 - val_loss: 0.6114 - val_accuracy: 0.7929 - lr: 1.0000e-04\n",
            "Epoch 16/20\n",
            "22/22 [==============================] - 51s 2s/step - loss: 0.0913 - accuracy: 0.9926 - val_loss: 0.6261 - val_accuracy: 0.8047 - lr: 1.0000e-04\n",
            "Epoch 17/20\n",
            "22/22 [==============================] - 49s 2s/step - loss: 0.0929 - accuracy: 0.9881 - val_loss: 0.6067 - val_accuracy: 0.8107 - lr: 1.0000e-04\n",
            "Epoch 18/20\n",
            "22/22 [==============================] - 53s 2s/step - loss: 0.0944 - accuracy: 0.9911 - val_loss: 0.6051 - val_accuracy: 0.8107 - lr: 2.0000e-05\n",
            "Epoch 19/20\n",
            "22/22 [==============================] - 52s 2s/step - loss: 0.0835 - accuracy: 0.9881 - val_loss: 0.5941 - val_accuracy: 0.8166 - lr: 2.0000e-05\n",
            "Epoch 20/20\n",
            "22/22 [==============================] - 56s 2s/step - loss: 0.0794 - accuracy: 0.9866 - val_loss: 0.5798 - val_accuracy: 0.8166 - lr: 2.0000e-05\n",
            "6/6 [==============================] - 8s 1s/step - loss: 0.5798 - accuracy: 0.8166\n",
            "Test accuracy: 0.8165680766105652\n",
            "Model converted to TFLite and saved as 'model.tflite'\n"
          ]
        }
      ]
    }
  ]
}